# Full workflow config: all parameters with consistent naming
# Usage: source workflow_config_full.env && ./run_retrieval_rerank_pipeline.sh
#
# Naming: TOP_K = retrieval depth (same concept in BM25/Dense/Hybrid/Reranker).
# Scripts use different flags internally (k_eval, topk, cap, candidate_limit) but
# all are set from TOP_K unless overridden by stage-specific vars below.

# ---------- Ground truth (eval metrics) ----------
# HAVE_GROUND_TRUTH=1   # set to 0 to skip all eval metrics (BM25, Dense, Hybrid, Rerank)

# ---------- Shared (paths + retrieval depth) ----------
WORKFLOW_OUTPUT_DIR=/path/to/output/full_run
TRAIN_JSON=/path/to/training.json
TEST_BATCH_JSONS="/path/to/test1.json  /path/to/test2.json"

# DOCS_JSONL: used by reranker (candidate docs) and by evidence steps (title/abstract lookup).
DOCS_JSONL=/path/to/literature.jsonl

# Retrieval depth: max docs per query (used by BM25 k_eval, Dense topk, Hybrid bm25_topk/cap/k_max_eval, Reranker candidate_limit)
TOP_K=5000
# Comma-separated K values for recall metrics (MeanR@K, etc.)
RECALL_KS=50,100,200,300,400,500,1000,2000,5000

# ---------- Index paths ----------
BM25_INDEX_PATH=/path/to/terrier_index_full
DENSE_INDEX_DIR=/path/to/dense_index_full

# ---------- BM25 + RM3 ----------
# BM25_INDEX_PATH (required) see above
# Optional overrides (leave unset to use defaults or TOP_K):
# BM25_JAVA_MEM=8g
# BM25_THREADS=4
# BM25_TOP_K=5000          # override retrieval depth for BM25 only (default: TOP_K)
# BM25_RM3_FEEDBACK_POOL=50 # k_feedback: docs used for RM3 expansion
# BM25_RM3_FB_DOCS=20       # RM3 fb_docs
# BM25_RM3_FB_TERMS=30      # RM25 fb_terms
# BM25_RM3_LAMBDA=0.6       # RM3 lambda
# BM25_INCLUDE_BASELINE=1   # set to 1 to also evaluate plain BM25 (--include_bm25)
# BM25_NO_EVAL=1            # set to 1 to skip metrics, only write runs
# BM25_SAVE_RUNS=1          # set to 1 to save run TSVs (default in pipeline)
# BM25_SAVE_PER_QUERY=1     # set to 1 for per-query CSV
# BM25_SAVE_ZERO_RECALL=1   # set to 1 for zero-recall report
# BM25_NO_EXCLUDE_TEST_QIDS=1  # set to 1 to keep test qids in train set

# ---------- Dense ----------
# DENSE_INDEX_DIR (required) see above
# DENSE_TOP_K=5000          # override retrieval depth for Dense (default: TOP_K)
# DENSE_EF_SEARCH=          # HNSW ef_search override (default from index meta.json)
# DENSE_EF_CAP=2000         # cap on ef_search for speed
# DENSE_BATCH_SIZE=256
# DENSE_DEVICE=cpu         # cpu, cuda, mps
# DENSE_MODEL_NAME=        # override SentenceTransformer model from index meta
# DENSE_NO_EVAL=1          # set to 1 to skip metrics, only write runs
# DENSE_SAVE_PER_QUERY=1   # set to 1 for per-query CSV

# ---------- Hybrid ----------
# HYBRID_CAP=5000          # fusion output cap (default: TOP_K)
# HYBRID_K_MAX_EVAL=5000   # max rank for evaluation (default: TOP_K)
# HYBRID_MODE=default      # default or sweep
# HYBRID_K_RRF=150         # RRF k (default mode)
# HYBRID_W_BM25=1.0
# HYBRID_W_DENSE=1.0
# HYBRID_WEIGHTS=1.0,1.0;2.0,1.0;1.0,2.0   # sweep mode weight pairs
# HYBRID_K_RRF_LIST=60,100 # sweep mode RRF k list
# HYBRID_JOBS=4            # parallel processes
# HYBRID_NO_EVAL=1         # set to 1 to skip metrics, only write runs
# HYBRID_NO_PLOTS=1        # set to 1 to disable plots
# HYBRID_SAVE_PLOTS=1      # set to 1 to force plots

# ---------- Reranker + Evidence (global: PubMed/literature corpus) ----------
# Set to run reranker and, after RRF fusion, to produce post_rerank_*.json and evidence/*_contexts.jsonl.
# RERANK_CANDIDATE_LIMIT=5000   # max candidates per query (default: TOP_K). Pipeline uses min(RERANK_CANDIDATE_LIMIT, HYBRID_CAP) then clamps to 100â€“2000.
# RERANK_KS_RECALL=50,100,200,300,400,500,1000,2000,5000  # default: RECALL_KS
# RERANK_MODEL=cross-encoder/ms-marco-MiniLM-L-12-v2
# RERANK_MODEL_DEVICE=auto     # auto, cuda, mps, cpu
# RERANK_MODEL_BATCH=16
# RERANK_MODEL_MAX_LENGTH=512
# RERANK_DISABLE_METRICS=1     # set to 1 when no ground truth
# RERANK_USE_MULTI_GPU=1
# RERANK_NUM_GPUS=0            # 0 = all

# ---------- RRF fusion (Hybrid + Rerank, top-10) ----------
# Enabled by default; pass --no-rrf-fusion to pipeline to skip.
# RRF_POOL_TOP=50             # union depth per list (top-N from BGE and Hybrid)
# RRF_K_RRF=60                # RRF K parameter in 1/(K+rank)
# RRF_W_BGE=0.8               # weight for BGE rerank scores
# RRF_W_HYBRID=0.2            # weight for Hybrid scores (default: 1 - RRF_W_BGE if unset)

# ---------- Evidence (post-rerank JSON + contexts JSONL) ----------
# Runs after RRF fusion when DOCS_JSONL is set. Query JSON is resolved per run from TRAIN_JSON and
# TEST_BATCH_JSONS: split name from run filename (e.g. 13B1_golden) is matched to basename without .json.

# ---------- Generation (LLM answers from contexts JSONL) ----------
# Runs after evidence when evidence/*_contexts.jsonl exist. Writes generation/json/*_answers.json
# and generation/jsonl/*_answers.jsonl. Requires QUERY_REWRITE_LLM_API_KEY or LLAMA_API_KEY in env or .env.
# GENERATION_CONCURRENCY=2           # max parallel LLM calls (default: 2)
# GENERATION_MAX_CONTEXTS=8          # cap on contexts in evidence block (default: 8)
# GENERATION_MAX_CHARS_PER_CONTEXT=2000   # truncation length per context (default: 2000)
# GENERATION_SLEEP=0.5               # seconds to sleep after each LLM call (default: 0.5)

